# the below code use opencv python
# another option to consider is scantailor-advanced
# https://github.com/4lex4/scantailor-advanced?tab=readme-ov-file

# modified code generated by ChatGPT
"""
split_spreads.py

Usage:
    python split_spreads.py --input_dir ./spreads --output_dir ./pages

Notes:
- Expects upright spreads (no rotation).
- For each input image it will:
    1) detect largest document contour and warp to a rectangle (perspective correct)
    2) compute a smoothed vertical projection and detect local minima (gutters)
    3) split into vertical segments at those minima; always covers full width
    4) save segments as spread_XXXX_pY.jpg

Tune parameters in the CONFIG section below.
"""

import os
import cv2
import numpy as np
from tqdm import tqdm
import argparse
import math
from datetime import datetime, timezone

# ----------------------------
# CONFIG / TUNABLE PARAMETERS
# ----------------------------
# Target warp size (approximately how wide/tall you want the rectified spread).
# Larger values increase accuracy but cost CPU. Keep aspect consistent with your scanned books.
TARGET_WIDTH = 4864
TARGET_HEIGHT = 3456

# Projection smoothing: kernel width (in pixels) for 1D smoothing of column sums.
SMOOTH_KERNEL = 101  # must be odd; increase if noisy

# Local minima detection:
MIN_DISTANCE_BETWEEN_SPLITS = 1200  # pixels; minimum allowed distance between splits
MIN_DEPTH_FACTOR = (
    0.55  # minima must be this fraction below median projection to qualify
)

# If no minima detected, fallback to a single center split (two pages)
FALLBACK_TO_CENTER = True

# Output JPEG quality
JPEG_QUALITY = 95  # it can be a quality from 0 to 100 (the higher is the better)


# ----------------------------
# Helper utilities
# ----------------------------
def ensure_dir(path):
    if not os.path.exists(path):
        os.makedirs(path)


def load_image(path):
    img = cv2.imdecode(np.fromfile(path, dtype=np.uint8), cv2.IMREAD_COLOR)
    if img is None:
        raise RuntimeError(f"failed to load image: {path}")
    return img


def save_jpeg(path, img, quality=JPEG_QUALITY):
    # Use imencode + tofile to support non-ascii paths on Windows
    ext = os.path.splitext(path)[1].lower()
    if ext not in [".jpg", ".jpeg", ".png"]:
        ext = ".jpg"
        path = path + ext
    params = (
        [int(cv2.IMWRITE_JPEG_QUALITY), quality] if ext in [".jpg", ".jpeg"] else []
    )
    _, enc = cv2.imencode(ext, img, params)
    enc.tofile(path)


# ----------------------------
# Step 1: Detect document & warp
# ----------------------------


# helper functions
def resize_with_aspect(img, target_w, target_h):
    """
    Resize the image to fit within the target width and height.
    """
    h, w = img.shape[:2]
    scale_w = target_w / w
    scale_h = target_h / h
    scale = min(scale_w, scale_h)
    nw, nh = int(w * scale), int(h * scale)
    resized = cv2.resize(img, (nw, nh), interpolation=cv2.INTER_AREA)
    out = np.full((target_h, target_w, 3), 255, dtype=np.uint8)
    # center it
    x = (target_w - nw) // 2
    y = (target_h - nh) // 2
    out[y : y + nh, x : x + nw] = resized
    return out


def order_points(pts):
    """
    Orders the points in a specific order: top-left, top-right, bottom-right, bottom-left.
    Assumes pts is a (4,2) array of float32.
    """
    s = pts.sum(axis=1)
    diff = np.diff(pts, axis=1).reshape(-1)
    tl = pts[np.argmin(s)]
    br = pts[np.argmax(s)]
    tr = pts[np.argmin(diff)]  # assume that height > width?
    bl = pts[np.argmax(diff)]
    return np.array([tl, tr, br, bl], dtype=np.float32)


# main function of step 1
def detect_largest_quad_and_warp(img, target_w=TARGET_WIDTH, target_h=TARGET_HEIGHT):
    """
    Detects the largest contour that approximates a quad and warps it to a rectangle.
    If detection fails, returns a centered-resized copy of the original (best-effort).
    """
    orig = img.copy()
    h0, w0 = img.shape[:2]

    # Preprocess
    # convert to grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    save_jpeg("debug_gray.jpg", gray)
    # use adaptive thresh + morphology to emphasize page contour
    # apply Gaussian blur to reduce noise
    blur = cv2.GaussianBlur(gray, (5, 5), 0)  # (5,5) is kernel for GaussianBlur
    save_jpeg("debug_blur.jpg", blur)
    # convert grayscale to black & white
    # adaptive threshold is calculated for each pixel based on local neighborhood
    th = cv2.adaptiveThreshold(
        blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 705, 15
    )  # maxValue=255, blockSize=35, C=15
    save_jpeg("debug_th.jpg", th)
    # create kernel for morphology
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 9))
    # fill small holes INSIDE the foreground objects
    # close = dilate -> erode
    # more info about morphological transformations:
    # https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html
    morp = cv2.morphologyEx(th, cv2.MORPH_CLOSE, kernel, iterations=1)
    save_jpeg("debug_morp.jpg", morp)

    # edges + contours
    # auto calculate thresholds for Canny alg
    edges = cv2.Canny(
        morp, 100, 250
    )  # lowThreshold=40, highThreshold=100 for Canny algorithm
    # find contours in a binary image
    # retrieve only the extreme outer contours
    # compress horizontal, vertical, and diagonal segments and leave only their end points
    cnts, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not cnts:
        # fallback: resize original to target aspect preserving content
        return resize_with_aspect(orig, target_w, target_h)

    # pick largest contour by area
    cnt = max(cnts, key=cv2.contourArea)
    peri = cv2.arcLength(cnt, True)  # calculate perimeter of contour
    # approximate contour to polygon with less vertices
    # so that the distance between original contour and approximated polygon is less than 2% of perimeter
    # using Douglas-Peucker algorithm
    approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)

    if len(approx) >= 4:
        # if we have more than 4 points, take convex hull then approx 4 points
        hull = cv2.convexHull(cnt)
        peri2 = cv2.arcLength(hull, True)
        approx2 = cv2.approxPolyDP(hull, 0.02 * peri2, True)
        if len(approx2) >= 4:
            approx = approx2

    if len(approx) == 4:
        pts = approx.reshape(4, 2).astype(np.float32)  # reshape to 4 points
        # order points to tl, tr, br, bl
        ordered = order_points(pts)
        # create destination points for perspective transform
        dst = np.array(
            [
                [0, 0],
                [target_w - 1, 0],
                [target_w - 1, target_h - 1],
                [0, target_h - 1],
            ],
            dtype=np.float32,
        )
        # compute perspective transform matrix
        M = cv2.getPerspectiveTransform(ordered, dst)
        # apply warp
        warped = cv2.warpPerspective(orig, M, (target_w, target_h))
        return warped
    else:
        # fallback: best-fit rectangle using bounding rect of largest contour
        x, y, w, h = cv2.boundingRect(cnt)
        padx = int(w * 0.02)
        pady = int(h * 0.02)
        x0 = max(0, x - padx)
        y0 = max(0, y - pady)
        x1 = min(w0, x + w + padx)
        y1 = min(h0, y + h + pady)
        crop = orig[y0:y1, x0:x1]
        return resize_with_aspect(crop, target_w, target_h)


# ----------------------------
# Step 2: Find split columns (possibly >2)
# ----------------------------
def smooth_1d(signal, kernel_size=SMOOTH_KERNEL):
    """
    Smooths a 1D signal using a simple moving average.
    """
    if kernel_size <= 1:
        return signal
    # ensure odd kernel size
    k = kernel_size if kernel_size % 2 == 1 else kernel_size + 1
    # simple moving average via convolution
    kernel = np.ones(k, dtype=np.float32) / k
    padded = np.pad(signal, (k // 2, k // 2), mode="edge")
    # slide kernel over signal
    sm = np.convolve(padded, kernel, mode="valid")
    return sm


def find_split_columns(img_rect):
    """
    Returns a sorted list of x coordinates where splits should occur (columns),
    including the leftmost (0) and rightmost (width) boundaries if needed.
    We return only the split columns (internal cuts), consumption later creates segments
    that cover the complete width.
    """
    gray = cv2.cvtColor(img_rect, cv2.COLOR_BGR2GRAY)
    # clip outer margins to avoid background influence
    h, w = gray.shape
    left = int(w * 0.03)
    right = w - left
    if right <= left + 10:
        left, right = 0, w  # extreme case: very narrow image

    crop = gray[:, left:right]

    # try to make the img in binary #########################
    blur = cv2.GaussianBlur(crop, (5, 5), 0)  # (5,5) is kernel for GaussianBlur
    save_jpeg("debug_blur.jpg", blur)
    # convert grayscale to black & white
    # adaptive threshold is calculated for each pixel based on local neighborhood
    th = cv2.adaptiveThreshold(
        blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 705, 15
    )  # maxValue=255, blockSize=35, C=15
    save_jpeg("debug_th.jpg", th)
    # create kernel for morphology
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 9))
    # fill small holes INSIDE the foreground objects
    # close = dilate -> erode
    # more info about morphological transformations:
    # https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html
    morp = cv2.morphologyEx(th, cv2.MORPH_CLOSE, kernel, iterations=1)
    save_jpeg("debug_morp.jpg", morp)
    #########################################################

    # projection: sum of intensities per column
    proj = np.sum(
        morp.astype(np.float32), axis=0
    )  # higher = brighter/more ink? depends
    # We expect gutter to be darker -> local minima in proj
    # Smooth the projection
    sm = smooth_1d(proj, kernel_size=SMOOTH_KERNEL)
    # Normalize
    sm = (sm - sm.min()) / (sm.max() - sm.min() + 1e-9)

    # Find local minima: compare each point to neighbors within +/-1
    minima_idx = []
    for i in range(1, len(sm) - 1):
        if sm[i] < sm[i - 1] and sm[i] < sm[i + 1]:
            minima_idx.append(i)

    # Filter minima by depth threshold relative to median
    median_val = np.median(sm)
    candidates = []
    for i in minima_idx:
        val = sm[i]
        if val < median_val * MIN_DEPTH_FACTOR:
            candidates.append(i)

    # Convert candidate indices to absolute columns in rectified image
    candidates = [int(left + i) for i in candidates]

    # Enforce minimum distance between splits
    candidates_sorted = sorted(candidates)
    filtered = []
    last = -10000
    for c in candidates_sorted:
        if c - last >= MIN_DISTANCE_BETWEEN_SPLITS:
            filtered.append(c)
            last = c
        else:
            # choose deeper minima among close ones (optional heuristic)
            # skip for simplicity
            pass

    # If no splits were found, fallback to center split (one internal split)
    if len(filtered) == 0 and FALLBACK_TO_CENTER:
        mid = w // 2
        filtered = [mid]

    # Return internal split columns only (not 0 or w)
    return filtered


# ----------------------------
# Step 3: Slice & save
# ----------------------------
def slice_and_save(img_rect, splits_internal, base_outpath, prefix="spread", idx=0):
    """
    splits_internal: list of x columns where internal splits occur (sorted)
    Will produce N segments where N = len(splits_internal) + 1
    Naming: {prefix}_{idx:04d}_p{segid}.jpg
    """
    h, w = img_rect.shape[:2]
    cuts = [0] + splits_internal + [w]
    saved = []
    for i in range(len(cuts) - 1):
        x0, x1 = cuts[i], cuts[i + 1]
        # ensure non-empty
        if x1 - x0 <= 10:
            continue  # too narrow, skip
        seg = img_rect[:, x0:x1]
        outname = f"{prefix}_{idx:04d}_p{i}.jpg"
        outpath = os.path.join(base_outpath, outname)
        save_jpeg(outpath, seg)
        saved.append((outpath, x0, x1))
    return saved


# ----------------------------
# Main batch function
# ----------------------------
def process_folder(input_dir, output_dir, prefix="spread"):
    ensure_dir(output_dir)
    files = sorted(
        [
            f
            for f in os.listdir(input_dir)
            if f.lower().endswith((".jpg", ".jpeg", ".png", ".tif", ".tiff"))
        ]
    )
    log_lines = []
    for i, fname in enumerate(tqdm(files, desc="spreads")):
        inpath = os.path.join(input_dir, fname)
        try:
            img = load_image(inpath)
        except Exception as e:
            print(f"ERROR loading {inpath}: {e}")
            continue

        # step 1: detect & warp
        # rect = detect_largest_quad_and_warp(img, TARGET_WIDTH, TARGET_HEIGHT)
        rect = img  # assume the content is the whole image
        save_jpeg("debug_rect.jpg", rect)
        # step 2: find splits
        splits = find_split_columns(rect)
        # step 3: slice & save
        saved = slice_and_save(rect, splits, output_dir, prefix=prefix, idx=i + 1)

        # log
        split_str = ",".join(str(x) for x in splits)
        log_lines.append(f"{fname}\t{len(saved)}\t{split_str}")

    # write log
    now = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
    with open(
        os.path.join(output_dir, f"split_log_{now}.tsv"), "w", encoding="utf8"
    ) as f:
        f.write("input_file\tsegments\tsplits_internal\n")
        for L in log_lines:
            f.write(L + "\n")


# ----------------------------
# CLI
# ----------------------------
if __name__ == "__main__":
    # debug = True
    # if debug:
    #     process_folder("./data/in/", "./data/out/", prefix="page")
    # else:
    p = argparse.ArgumentParser(
        description="Batch-split spread images into page segments."
    )
    p.add_argument("--input_dir", required=True, help="Folder with spread images")
    p.add_argument("--output_dir", required=True, help="Folder to save page segments")
    p.add_argument("--prefix", default="spread", help="Output filename prefix")
    args = p.parse_args()
    process_folder(args.input_dir, args.output_dir, prefix=args.prefix)
